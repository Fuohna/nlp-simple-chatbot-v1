{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413ca3a0-68d2-4b1a-8832-96d3f201f88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpruned.word2vec.txt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('pruned.word2vec.txt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mmodels/pruned.word2vec.txt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\tuanna63/nltk_data'\n    - 'c:\\\\Users\\\\tuanna63\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\tuanna63\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\tuanna63\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\tuanna63\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4252\\119858693.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mword2vec_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/pruned.word2vec.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2vec_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tuanna63\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpruned.word2vec.txt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('pruned.word2vec.txt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mmodels/pruned.word2vec.txt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\tuanna63/nltk_data'\n    - 'c:\\\\Users\\\\tuanna63\\\\anaconda3\\\\nltk_data'\n    - 'c:\\\\Users\\\\tuanna63\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\tuanna63\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\tuanna63\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('brown')\n",
    "from nltk.test.gensim_fixt import setup_module\n",
    "setup_module()\n",
    "\n",
    "import pathlib\n",
    "current_folder = pathlib.Path().resolve()\n",
    "model_file = pathlib.Path('models/english.word2vec.txt')\n",
    "print(model_file.is_file())\n",
    "\n",
    "\n",
    "# print(\"Model folder: \" + model_folder)\n",
    "\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from nltk.data import find\n",
    "word2vec_sample = str(find('models/english.word2vec.txt'))\n",
    "print(word2vec_sample)\n",
    "\n",
    "print('Start loading at time ' + time.ctime())\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)\n",
    "print('Finish loading at time ' + time.ctime())\n",
    "\n",
    "# print(model['university'])\n",
    "print(model.most_similar(positive=['treasure'], topn = 3))\n",
    "sim = model.cosine_similarities(model['cat'], np.array([model['kitten']]))\n",
    "print(\"Sim between uni vs school = \" + str(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f52c6b-269e-456c-b26c-b7992b2373cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sim between dog and puppy = \" + str(model.cosine_similarities(model['dog'], np.array([model['puppy']]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e3f21-7702-4ff7-a985-f08a271e1af5",
   "metadata": {},
   "source": [
    "* MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a28101-4724-4298-9461-fa0258a82d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d8cce-7100-4745-a7bd-4d575145e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.most_similar(positive=['article'], topn = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd8dce-cf35-429a-a302-9bcc9700e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "nltk.download(\"words\")\n",
    "word_list = words.words()\n",
    "print(len(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d6bf2c-c366-4c18-a84c-a2e7c45af202",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.most_similar(positive=['witch'], topn = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eeddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab92b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c69d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "42baff8518b50338084708a96b14cc873b9324e5a615746f6aa55d093668d6d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
